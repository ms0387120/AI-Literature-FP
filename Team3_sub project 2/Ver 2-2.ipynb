{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character: \n",
      "['水妖', '男孩', '小姑娘']\n",
      "Location: \n",
      "['井里', '山']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.stanford_segmenter import StanfordSegmenter\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse import corenlp\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk import Tree\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/jdk-11.0.2.jdk/Contents/Home/bin/java\" \n",
    "os.environ[\"CLASSPATH\"] = \"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars\"\n",
    "os.environ[\"STANFORD_MODELS\"] = \"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/models\"\n",
    "\n",
    "### Input reading\n",
    "f = open(\"女水妖.txt\", \"r\")\n",
    "\n",
    "#==========抽取元素==========\n",
    "## NN_Default\n",
    "NN_except=['個','誰','時','兩','一','房子']\n",
    "vocal = ['砰','咚']\n",
    "\n",
    "loc = ['稻草屋','水潭','城堡','木屋子','磚屋','森林','高塔','河','奶奶家','王宮','花園','廚房','家','井里','山']\n",
    "\n",
    "char_except = ['好孩子','身邊說','人們心中', '美好願望', '好幾', '個個', '小女兒', '美如天仙','小公主','嚴冬時節', '大雪片', '窗子邊', '針線活兒', '寒風捲著', '捲著雪片', '烏木窗臺', '針口流了', '三點血滴', '飄進窗子', '鮮紅血滴', '烏木窗臺', '血一樣', '這窗子','他們','你們','我們','弟弟','兄妹','女水妖','斧子']\n",
    "family_member = ['祖父','祖母','爺爺','奶奶','外公','外婆','爸爸','媽媽','叔叔','舅舅','阿姨','嬸嬸','後母','姊姊','姐姐','繼母','姊妹','大哥','二哥','小弟']\n",
    "passerby = ['公主','王子','女巫','狐狸','國王','皇后','獵人','王后','小矮人','魔鏡','野狼','妖精','精靈','僕人','灰姑娘','大臣','水妖','男孩']\n",
    "\n",
    "Time = ['清晨','白天','黃昏','晚上']\n",
    "\n",
    "## Character\n",
    "### 1. 文章內所有角色\n",
    "temp = []\n",
    "char=[]\n",
    "w = []\n",
    "t = []\n",
    "\n",
    "\n",
    "for x in f:\n",
    "    \n",
    "    seg_list = jieba.cut(x)\n",
    "    tokens = \"/\".join(seg_list)\n",
    "    tokenizer = tokens.split(\"/\")\n",
    "    #print(tokenizer)\n",
    "\n",
    "    zh_tagger = StanfordPOSTagger('chinese-nodistsim.tagger')\n",
    "    #print(zh_tagger.tag(tokens.split(\"/\")))\n",
    "    for _, word_and_tag in  zh_tagger.tag(tokens.split(\"/\")):\n",
    "        word, tag = word_and_tag.split('#')\n",
    "        #print(word,tag)\n",
    "        w.append(word)\n",
    "        t.append(tag)\n",
    "        \n",
    "for i in range(1,len(w)):\n",
    "    if(t[i-1]==\"NN\" and t[i]==\"NN\"):\n",
    "        a = w[i-1]+w[i]\n",
    "        if(a not in char):\n",
    "            temp.append(a)\n",
    "    \n",
    "    elif(t[i-1]==\"JJ\" and t[i]==\"NN\"):\n",
    "        a = w[i-1]+w[i]\n",
    "        if(a not in char):\n",
    "            temp.append(a)\n",
    "    if(t[i]==\"NN\" or t[i]==\"NR\"):\n",
    "        a = w[i]\n",
    "        if(a not in char):\n",
    "            temp.append(a)\n",
    "\n",
    "i = 0\n",
    "while i < len(temp):\n",
    "    if temp[i] in char_except:\n",
    "        del temp[i]\n",
    "    else:\n",
    "        i += 1\n",
    "            \n",
    "#print(temp)\n",
    "\n",
    "### 2. 找出親人關係\n",
    "for i in range(len(temp)):\n",
    "    if(temp[i] in family_member and temp[i] not in char):\n",
    "        char.append(temp[i])\n",
    "#print(char)\n",
    "\n",
    "### 3. 找出第三方角色\n",
    "for i in range(len(temp)):\n",
    "    if(temp[i] in passerby and temp[i] not in char):\n",
    "        char.append(temp[i])\n",
    "#print(char)\n",
    "\n",
    "### 4. 計算重要角色 Top3\n",
    "from collections import Counter\n",
    "word_counts = Counter(temp)\n",
    "top_three = word_counts.most_common(3)\n",
    "#print(top_three)\n",
    "\n",
    "### 5. 增加可能重要或未偵測出的角色\n",
    "for i in range(len(top_three)):\n",
    "    if(top_three[i][0] not in loc and top_three[i][0] not in family_member and top_three[i][0] not in char and top_three[i][0] not in NN_except):\n",
    "        char.insert(0+i, top_three[i][0])\n",
    "#print(char)\n",
    "\n",
    "### 6. 移除重複\n",
    "i = 0\n",
    "while i < len(char):\n",
    "    if char[i] in char_except:\n",
    "        del char[i]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "### character output\n",
    "print(\"Character: \")\n",
    "print(char)\n",
    "\n",
    "## Location\n",
    "### 1. 從名詞（temp）去查找對照的 loc_default，並存在 loc_temp\n",
    "from collections import Counter\n",
    "\n",
    "loc_temp = []\n",
    "\n",
    "for i in range(len(temp)):\n",
    "    if(temp[i] in loc):\n",
    "        loc_temp.append(temp[i])\n",
    "\n",
    "word_counts = Counter(loc_temp)\n",
    "        \n",
    "#print(loc_temp)\n",
    "\n",
    "### 2. 從 loc_temp 整理\n",
    "word_counts = Counter(loc_temp)\n",
    "loc_counts = word_counts.most_common(len(loc_temp))\n",
    "#print(loc_counts)\n",
    "\n",
    "loc_set = []\n",
    "\n",
    "for i in range(len(loc_counts)):\n",
    "    loc_set.append(loc_counts[i][0])\n",
    "\n",
    "### Location output\n",
    "print(\"Location: \")\n",
    "print(loc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"女水妖.txt\",\"r\")\n",
    "outside = 0\n",
    "inside = 0\n",
    "\n",
    "for x in f:\n",
    "    if(\"「\" in x):\n",
    "        for i in range(len(loc_set)):\n",
    "            if(loc_set[i] in x):\n",
    "                inside+=1\n",
    "    else:\n",
    "        for i in range(len(loc_set)):\n",
    "            if(loc_set[i] in x):\n",
    "                outside+=1\n",
    "\n",
    "print((inside,outside))\n",
    "\n",
    "if(inside>=outside): # \"「\" in x\n",
    "    inside = True\n",
    "else: # \"「\" not in x\n",
    "    inside = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Scene: 時/ 白天     景/ 井里\n",
      "從前有兄妹兩人在井邊玩耍，不小心掉進了井里。\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:263: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.StanforCoreNLPDependencyParser\u001b[0m instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "水妖: 現在你們可是在我的手裡了，替我好好幹活吧！\n",
      "她給小姑娘一把亂糟糟的臟亞麻要她紡，給她一個漏了的水桶要她打水\n",
      "\n",
      "男孩子則被迫去砍伐木頭，可斧子是鈍的，根本砍不動樹。\n",
      "\n",
      "至於吃的，除了像石頭一般硬的面疙瘩就再也沒有別的了。\n",
      "\n",
      "孩子們忍無可忍，在一個星期天，趁水妖上教堂的工夫，兄妹倆悄悄地溜走了。\n",
      "\n",
      "水妖從教堂回來，發現小鳥們飛走了，撒腿就追。\n",
      "\n",
      "================================\n",
      "Scene: 時/ 白天     景/ 山\n",
      "遠遠看到水妖追來，姑娘便朝身後扔了一把刷子，刷子頓時變成了一座長滿荊棘的大山，水妖只好艱難地往上爬，終於爬過來了。\n",
      "\n",
      "孩子們一看不好，男孩又扔出一把梳子，那梳子頓時變成成千上萬顆牙齒，可是水妖還是穩穩噹噹地跨過來了。\n",
      "\n",
      "小姑娘又扔了一塊鏡子，鏡子變成一座光滑的山峰，任水妖怎麼爬也難以爬上來。\n",
      "\n",
      "水妖: 還是快些回家象把斧子來把這玻璃山砍成兩半吧。\n",
      "可是等她取來斧子把玻璃山砍開時，小兄妹早已逃得遠遠的了。\n",
      "\n",
      "================================\n",
      "Scene: 時/ 白天     景/ 井里\n",
      "女水妖只好又回到井里去了。\n",
      "============The End============\n"
     ]
    }
   ],
   "source": [
    "#==========生成劇本==========\n",
    "# Latest Version\n",
    "\n",
    "last_loc = \"\"\n",
    "last_time=\"\"\n",
    "start=True\n",
    "detect_print=True\n",
    "\n",
    "### Input reading\n",
    "f = open(\"女水妖.txt\", \"r\")\n",
    "\n",
    "for x in f:\n",
    "    \n",
    "    # Time\n",
    "    # Night\n",
    "    if('天黑' in x or '晚上' in x):\n",
    "        time = Time[3]\n",
    "    \n",
    "    #evening    \n",
    "    elif('黃昏' in x or '夕陽' in x):\n",
    "        time = Time[2]\n",
    "        \n",
    "    #morning\n",
    "    elif('晨' in x):\n",
    "        time = Time[0]\n",
    "        \n",
    "    # default: 白天\n",
    "    else:\n",
    "        time = Time[1]\n",
    "        \n",
    "    #Location\n",
    "    if(inside==True):\n",
    "        if('「'  in x):\n",
    "            for i in range(len(loc_set)): \n",
    "            # 地點 case1: 一開始\n",
    "                if(loc_set[i] in x and loc_set[i]!=last_loc and start==True):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+loc_set[i])\n",
    "                    last_loc = loc_set[i]\n",
    "                    last_time = time\n",
    "                    start=False\n",
    "                    break\n",
    "                \n",
    "                if(start==True):\n",
    "                    print(\"================================\")\n",
    "                    last_loc = '家'\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+last_loc)\n",
    "                    start = False\n",
    "                    break\n",
    "            \n",
    "            # 地點 case2: 家以外的場景\n",
    "                if(loc_set[i] in x and loc_set[i]!=last_loc and loc_set[i]!=\"家\"):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+loc_set[i])\n",
    "                    last_loc = loc_set[i]\n",
    "                    last_time = time\n",
    "                    break\n",
    "                \n",
    "                '''if(time!=last_time):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+last_loc)\n",
    "                    last_time = time'''\n",
    "    \n",
    "    else: \n",
    "        #outside\n",
    "        if('「'  not in x):\n",
    "            for i in range(len(loc_set)): \n",
    "            # 地點 case1: 一開始\n",
    "                if(loc_set[i] in x and loc_set[i]!=last_loc and start==True):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+loc_set[i])\n",
    "                    last_loc = loc_set[i]\n",
    "                    last_time = time\n",
    "                    start=False\n",
    "                    break\n",
    "                \n",
    "                if(start==True):\n",
    "                    print(\"================================\")\n",
    "                    last_loc = '家'\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+last_loc)\n",
    "                    start = False\n",
    "                    break\n",
    "            \n",
    "            # 地點 case2: 家以外的場景\n",
    "                if(loc_set[i] in x and loc_set[i]!=last_loc and loc_set[i]!=\"家\"):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+loc_set[i])\n",
    "                    last_loc = loc_set[i]\n",
    "                    last_time = time\n",
    "                    break\n",
    "                \n",
    "                '''if(time!=last_time):\n",
    "                    print(\"================================\")\n",
    "                    print(\"Scene: 時/ \"+time+\"     景/ \"+last_loc)\n",
    "                    last_time = time'''\n",
    "            \n",
    "    \n",
    "        # 強迫換景\n",
    "        if('隔天' in x or '第二天' in x):\n",
    "            print(\"================================\")\n",
    "            print(\"Scene: 時/ \"+time+\"     景/ \"+last_loc)\n",
    "            last_time = time\n",
    "\n",
    "       \n",
    "    if(\"「\" in x):\n",
    "        # case 3-2\n",
    "        if(x[0]==\"「\"):\n",
    "            upper = (x.split(\"「\"))\n",
    "            two = upper[1]\n",
    "\n",
    "            if(len(upper)>2):\n",
    "                dia1 = upper[1].split(\"」\")[0]\n",
    "                sentence1 =  two.split(\"」\")[1]\n",
    "                sentence2 = sentence1\n",
    "                dia2 = upper[2].split(\"」\")[0]\n",
    "                \n",
    "                sentence = []\n",
    "                sentence.append(sentence1)\n",
    "                sentence.append(sentence2)\n",
    "\n",
    "                dialogue = []\n",
    "                dialogue.append(dia1)\n",
    "                dialogue.append(dia2)\n",
    "\n",
    "                for i in range(2):\n",
    "\n",
    "                    seg_list = jieba.cut(sentence[i]) \n",
    "                    tokens = \"/\".join(seg_list)\n",
    "                    tokenizer = tokens.split(\"/\")\n",
    "                    #print(tokenizer)\n",
    "                    for j in range(len(char)):\n",
    "                        if(char[j] in tokenizer):\n",
    "                            A = char[j]\n",
    "                            break\n",
    "                    B=A\n",
    "\n",
    "                    zh_dependency_parser = StanfordDependencyParser(\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser-3.9.2-models.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/models/chineseFactored.ser.gz\")\n",
    "                    ans = list(zh_dependency_parser.parse(tokens.split(\"/\")))\n",
    "                    for row in ans[0].triples():\n",
    "                        if(row[1]==\"nsubj\" and row[2][0] in char):\n",
    "                            A = row[2][0]\n",
    "                            #print(\"from: \"+A)\n",
    "                        elif(row[1]==\"compound:nn\" and row[2][0] in char_except):\n",
    "                            B = row[2][0]\n",
    "                            #print(\"to: \"+B)    \n",
    "                for k in range(len(vocal)):\n",
    "                    if(vocal[i] in dialogue[i]):\n",
    "                        detect_print = False\n",
    "                        break\n",
    "                \n",
    "                if(detect_print):\n",
    "                    print(A+\": \"+dialogue[i])\n",
    "                    print(sentence[i])\n",
    "                else:\n",
    "                    detect_print = True\n",
    "                \n",
    "                \n",
    "            # case 3-1\n",
    "            else:\n",
    "                dialogue = upper[1].split(\"」\")[0]\n",
    "                sentence = upper[1].split(\"」\")[1]\n",
    "                \n",
    "                seg_list = jieba.cut(sentence) \n",
    "                tokens = \"/\".join(seg_list)\n",
    "                tokenizer = tokens.split(\"/\")\n",
    "                #print(tokenizer)\n",
    "                for j in range(len(char)):\n",
    "                        if(char[j] in tokenizer):\n",
    "                            A = char[j]\n",
    "                            break\n",
    "                B=A\n",
    "                \n",
    "                zh_dependency_parser = StanfordDependencyParser(\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser-3.9.2-models.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/models/chineseFactored.ser.gz\")\n",
    "                ans = list(zh_dependency_parser.parse(tokens.split(\"/\")))\n",
    "                \n",
    "                for row in ans[0].triples():\n",
    "                    if(row[1]==\"nsubj\" and row[2][0] in char):\n",
    "                        A = row[2][0]\n",
    "                        #print(\"from: \"+A)\n",
    "                    elif(row[1]==\"compound:nn\" and row[2][0] in char_except):\n",
    "                        B = row[2][0]\n",
    "                        #print(\"to: \"+B)\n",
    "\n",
    "                for k in range(len(vocal)):\n",
    "                    if(vocal[k] in dialogue):\n",
    "                        detect_print = False\n",
    "                        break\n",
    "                \n",
    "                if(detect_print):\n",
    "                        print(A+\": \"+dialogue)\n",
    "                        #print(sentence)\n",
    "                else:\n",
    "                    detect_print = True\n",
    "                   \n",
    "        # case 1, 2\n",
    "        else:\n",
    "            upper = (x.split(\"「\"))\n",
    "            two = upper[1]\n",
    "\n",
    "            # case 2\n",
    "            if(len(upper)>2):\n",
    "                sentence1 = upper[0]\n",
    "                dia1 =  upper[1].split(\"」\")[0]\n",
    "                sentence2 = (two.split(\"」\"))[1]\n",
    "                dia2 = upper[2].split(\"」\")[0]\n",
    "                \n",
    "                sentence = []\n",
    "                sentence.append(sentence1)\n",
    "                sentence.append(sentence2)\n",
    "\n",
    "                dialogue = []\n",
    "                dialogue.append(dia1)\n",
    "                dialogue.append(dia2)\n",
    "\n",
    "                for i in range(2):\n",
    "\n",
    "                    seg_list = jieba.cut(sentence[i]) \n",
    "                    tokens = \"/\".join(seg_list)\n",
    "                    tokenizer = tokens.split(\"/\")\n",
    "                    #print(tokenizer)\n",
    "                    for j in range(len(char)):\n",
    "                        if(char[j] in tokenizer):\n",
    "                            A = char[j]\n",
    "                            break\n",
    "                    B=A\n",
    "\n",
    "                    zh_dependency_parser = StanfordDependencyParser(\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser-3.9.2-models.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/models/chineseFactored.ser.gz\")\n",
    "                    ans = list(zh_dependency_parser.parse(tokens.split(\"/\")))\n",
    "                    for row in ans[0].triples():\n",
    "                        if(row[1]==\"nsubj\" and row[2][0] in char):\n",
    "                            A = row[2][0]\n",
    "                            #print(\"from: \"+A)\n",
    "                        elif(row[1]==\"compound:nn\" and row[2][0] in char_except):\n",
    "                            B = row[2][0]\n",
    "                            #print(\"to: \"+B)\n",
    "                \n",
    "                for k in range(len(vocal)):\n",
    "                    if(vocal[k] in dialogue[i]):\n",
    "                        detect_print = False\n",
    "                        break\n",
    "                \n",
    "                if(detect_print):\n",
    "                        print(sentence[i])\n",
    "                        print(A+\": \"+dialogue[i])\n",
    "                else:\n",
    "                    detect_print = True\n",
    "                \n",
    "            # case 1\n",
    "            else:\n",
    "                sentence = upper[0]\n",
    "                dialogue = upper[1].split(\"」\")[0]\n",
    "                \n",
    "                seg_list = jieba.cut(sentence) \n",
    "                tokens = \"/\".join(seg_list)\n",
    "                tokenizer = tokens.split(\"/\")\n",
    "                #print(tokenizer)\n",
    "                for j in range(len(char)):\n",
    "                        if(char[j] in tokenizer):\n",
    "                            A = char[j]\n",
    "                            break\n",
    "                B=A\n",
    "\n",
    "                zh_dependency_parser = StanfordDependencyParser(\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/jars/stanford-parser-3.9.2-models.jar\",\"/Users/sumeiru/Desktop/StanfordNLP/StanfordNLP/models/chineseFactored.ser.gz\")\n",
    "                ans = list(zh_dependency_parser.parse(tokens.split(\"/\")))\n",
    "                \n",
    "                for row in ans[0].triples():\n",
    "                    if(row[1]==\"nsubj\" and row[2][0] in char):\n",
    "                        A = row[2][0]\n",
    "                        #print(\"from: \"+A)\n",
    "                    elif(row[1]==\"compound:nn\" and row[2][0] in char_except):\n",
    "                        B = row[2][0]\n",
    "                        #print(\"to: \"+B)\n",
    "\n",
    "                for k in range(len(vocal)):\n",
    "                    if(vocal[k] in dialogue):\n",
    "                        detect_print = False\n",
    "                        break\n",
    "                \n",
    "                if(detect_print):\n",
    "                        print(A+\": \"+dialogue)\n",
    "                else:\n",
    "                    detect_print = True\n",
    "                \n",
    "    else:\n",
    "        print(x)\n",
    "        \n",
    "print(\"============The End============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_set = ['稻草屋', '家', '木屋子', '磚屋']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在遙遠的古代，人們心中的美好願望往往能夠變成現實。\n",
      "\n",
      "就在那個令人神往的時代，曾經有過一位國王。\n",
      "\n",
      "國王有好幾個女兒，個個都長得非常美麗；尤其是他的小女兒，更是美如天仙，就連見多識廣的太陽，每次照在她臉上時，都對她的美麗感到驚詫不已。\n",
      "\n",
      "國王的宮殿附近，有一片幽暗的大森林。\n",
      "\n",
      "在這片森林中的一棵老椴樹下，有一個水潭，水潭很深。\n",
      "\n",
      "在天熱的時候，小公主常常來到這片森林，坐在清涼的水潭邊上。\n",
      "\n",
      "她坐在那裡感到無聊的時候，就取出一隻金球，把金球拋向空中，然後再用手接住。\n",
      "\n",
      "這成了她最喜愛的游戲。\n",
      "\n",
      "不巧的是，有一次，小公主伸出兩隻小手去接金球，金球卻沒有落進她的手裡，而是掉到了地上，而且一下子就滾到了水潭裡。\n",
      "\n",
      "小公主兩眼緊緊地盯著金球，可是金球忽地一下子在水潭裡就沒影兒了。\n",
      "\n",
      "因為水潭裡的水很深，看不見底，小公主就哭了起來，她的哭聲越來越大，哭得傷心極了。\n",
      "\n",
      "哭著哭著，小公主突然聽見有人大聲說：「哎呀，公主，您這是怎麼啦？您這樣嚎啕大哭，就連石頭聽了都會心疼的呀。」\n",
      "\n",
      "聽了這話，小公主四處張望，想弄清楚說話聲是從哪兒傳來的，不料卻發現一隻青蛙，從水裡伸出他那醜陋不堪的肥嘟嘟的大腦袋。\n",
      "\n",
      "「啊！原來是你呀，游泳健將」小公主對青蛙說道，「我在這兒哭，是因為我的金球掉進水潭裡去了。」\n",
      "\n",
      "「好啦，不要難過，別哭了，」青蛙回答說，「我有辦法幫助您。要是我幫您把您的金球撈出來，您拿什麼東西來回報我呢？」\n",
      "\n",
      "「親愛的青蛙，你要什麼東西都成呵，」小公主回答說，「我的衣服、我的珍珠和寶石、甚至我頭上戴著的這頂金冠，都可以給你。」\n",
      "\n",
      "聽了這話，青蛙對小公主說：「您的衣服、您的珍珠、您的寶石，還有您的金冠，我哪樣都不想要。不過，要是您喜歡我，讓我做您的好朋友，我們一起游戲，吃飯的時候讓我和您同坐一張餐桌，用您的小金碟子吃東西，用您的小高腳杯飲酒，晚上還讓我睡在您的小床上；要是您答應所有這一切的話，我就潛到水潭裡去，把您的金球撈出來。」\n",
      "\n",
      "「好的，太好了，」小公主說，「只要你願意把我的金球撈出來，你的一切要求我都答應。」\n",
      "\n",
      "小公主雖然嘴上這麼說，心裡卻想：「這隻青蛙可真夠傻的，盡胡說八道！他只配蹲在水潭裡，和其他青蛙一起呱呱叫，怎麼可能做人的好朋友呢？」\n",
      "\n",
      "青蛙得到了小公主的許諾之後，把腦袋往水裡一扎，就潛入了水潭。\n",
      "\n",
      "過了不大一會兒，青蛙嘴裡銜著金球，浮出了水面，然後把金球吐在草地上。\n",
      "\n",
      "小公主重又見到了自己心愛的玩具，心裡別提有多高興了。\n",
      "\n",
      "她把金球揀了起來，撒腿就跑。\n",
      "\n",
      "「別跑！別跑！」青蛙大聲叫道，「帶上我呀！我可跑不了您那麼快。」\n",
      "\n",
      "儘管青蛙扯著嗓子拼命叫喊，可是沒有一點兒用。\n",
      "\n",
      "小公主對青蛙的喊叫根本不予理睬，而是徑直跑回了家，並且很快就把可憐的青蛙忘記得一干二凈。\n",
      "\n",
      "青蛙只好蹦蹦跳跳地又回到水潭裡去。\n",
      "\n",
      "第二天，小公主跟國王和大臣們剛剛坐上餐桌，才開始用她的小金碟進餐，突然聽見啪啦啪啦的聲音。\n",
      "\n",
      "隨著聲響，有個什麼東西順著大理石臺階往上跳，到了門口時，便一邊敲門一邊大聲嚷嚷：「小公主，快開門！」聽到喊聲，小公主急忙跑到門口，想看看是誰在門外喊叫。\n",
      "\n",
      "打開門一看，原來是那隻青蛙，正蹲在門前。\n",
      "\n",
      "小公主見是青蛙，猛然把門關上，轉身趕緊回到座位，心裡害怕極了。\n",
      "\n",
      "國王發現小公主一副心慌意亂的樣子，就問小公主：「孩子，你怎麼會嚇成這個樣子？該不是門外有個巨人要把你抓走吧？」\n",
      "\n",
      "「啊，不是的，」小公主回答說，「不是什麼巨人，而是一隻討厭的青蛙。」\n",
      "\n",
      "「青蛙想找你做什麼呢？」國王問。\n",
      "\n",
      "「唉！我的好爸爸，昨天，我到森林里去了。坐在水潭邊上玩的時候，金球掉到水潭裡去了，於是我就哭了。我哭得很傷心，青蛙就替我把金球撈了上來。因為青蛙請求我做他的朋友，我就答應了，可是我壓根兒沒有想到，他會從水潭裡爬出來，爬這麼遠的路到這兒來。現在他就在門外呢，想要上咱這兒來。」小公主回答。\n",
      "\n",
      "正說著話的當兒，又聽見了敲門聲，接著是大聲的喊叫：「小公主啊我的愛，快點兒把門打開！愛你的人已到來，快點兒把門打開！你不會忘記昨天，老椴樹下水潭邊，潭水深深球不見，是你親口許諾言。」\n",
      "\n",
      "國王聽了之後對小公主說，「你決不能言而無信，快去開門讓他進來。」小公主走過去把門打開，青蛙蹦蹦跳跳地進了門，然後跟著小公主來到座位前，接著大聲叫道，「把我抱到你身旁呀！」\n",
      "\n",
      "小公主聽了嚇得發抖，國王卻吩咐她照青蛙說的去做。\n",
      "\n",
      "青蛙被放在了椅子上，可心裡不太高興，想到桌子上去。 \n",
      "\n",
      "上了桌子之後又說，「把您的小金碟子推過來一點兒好嗎？這樣我們就可以一快兒吃啦。」\n",
      "\n",
      "很顯然，小公主很不情願這麼做，可她還是把金碟子推了過去。\n",
      "\n",
      "青蛙吃得津津有味，可小公主卻一點兒胃口都沒有。\n",
      "\n",
      "終於，青蛙開口說，「我已經吃飽了。現在我有點累了，請把我抱到您的小卧室去，鋪好您的緞子被蓋，然後我們就寢吧。」\n",
      "\n",
      "小公主害怕這隻冷冰冰的青蛙，連碰都不敢碰一下。\n",
      "\n",
      "一聽他要在自己整潔漂亮的小床上睡覺，就哭了起來。\n",
      "\n",
      "國王見小公主這個樣子，就生氣地對她說，「在我們困難的時候幫助過我們的人，不論他是誰，過後都不應當受到鄙視。」\n",
      "\n",
      "於是，小公主用兩隻纖秀的手指把青蛙挾起來，帶著他上了樓，把他放在卧室的一個角落裡。 可是她剛剛在床上躺下，青蛙就爬到床邊對她說，「我累了，我也想在床上睡覺。請把我抱上來，要不然我就告訴您父親。」\n",
      "\n",
      "一聽這話，小公主勃然大怒，一把抓起青蛙，朝牆上死勁兒摔去。\n",
      "\n",
      "「現在你想睡就去睡吧，你這個醜陋的討厭鬼！」\n",
      "\n",
      "誰知他一落地，已不再是什麼青蛙，卻一下子變成了一位王子：一位兩眼炯炯有神、滿面笑容的王子。\n",
      "\n",
      "直到這時候，王子才告訴小公主，原來他被一個狠毒的巫婆施了魔法，除了小公主以外，誰也不能把他從水潭裡解救出來。\n",
      "\n",
      "於是，遵照國王的旨意，他成為小公主親密的朋友和伴侶，明天，他們將一道返回他的王國。\n",
      "\n",
      "第二天早上，太陽爬上山的時候，一輛八匹馬拉的大馬車已停在了門前，馬頭上都插著潔白的羽毛，一晃一晃的，馬身上套著金光閃閃的馬具。\n",
      "\n",
      "車後邊站著王子的僕人--忠心耿耿的亨利。\n",
      "\n",
      "亨利的主人被變成一隻青蛙之後，他悲痛欲絕，於是他在自己的胸口套上了三個鐵箍，免得他的心因為悲傷而破碎了。\n",
      "\n",
      "馬車來接年輕的王子回他的王國去。\n",
      "\n",
      "忠心耿耿的亨利扶著他的主人和王妃上了車廂，然後自己又站到了車後邊去。\n",
      "\n",
      "他們上路後剛走了不遠，突然聽見噼噼啦啦的響聲，好像有什麼東西斷裂了。\n",
      "\n",
      "路上，噼噼啦啦聲響了一次又一次，每次王子和王妃聽見響聲，都以為是車上的什麼東西壞了。\n",
      "\n",
      "其實不然，忠心耿耿的亨利見主人是那麼地幸福，因而感到欣喜若狂，於是那幾個鐵箍就從他的胸口上一個接一個地崩掉了。\n",
      "(6, 11)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"青蛙王子.txt\",\"r\")\n",
    "outside = 0\n",
    "inside = 0\n",
    "\n",
    "for x in f:\n",
    "    print(x)\n",
    "    if(\"「\" in x):\n",
    "        for i in range(len(loc_set)):\n",
    "            if(loc_set[i] in x):\n",
    "                inside+=1\n",
    "    else:\n",
    "        for i in range(len(loc_set)):\n",
    "            if(loc_set[i] in x):\n",
    "                outside+=1\n",
    "\n",
    "print((inside,outside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
