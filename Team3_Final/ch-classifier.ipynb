from gensim.models import KeyedVectors
import numpy as np

ch = KeyedVectors.load_word2vec_format("cna.word2vec.bin", binary=True)

char = {'祖父','祖母','爺爺','奶奶','外公','外婆','爸爸','媽媽','叔叔','舅舅','阿姨','嬸嬸','後母','姊姊','姐姐','繼母','姊妹',
        '大哥','二哥','小弟', '公主','王子','女巫','狐狸','國王','皇后','獵人','王后','小矮人','魔鏡','野狼','妖精','精靈','僕人',
        '灰姑娘','大臣', '媽媽', '大哥', '二哥', '小弟', '野狼'}

loc = {'奶奶家', '家','森林', '稻草屋', '家', '木屋子', '磚屋', '稻草屋','水潭','城堡','木屋子','磚屋','森林','高塔',
       '河','奶奶家','王宮','花園','廚房','家','井里','山', '教堂'}


other = {'生活', '勤勞', '稻草', '笨蛋', '骨頭', '睡覺', '聲音', '萬歲', '全身'}

orig_loc = loc.copy()
for i in orig_loc:
    if i in ch.vocab:
        temp = ch.most_similar(i)
        for word, simi in temp:
            loc.add(word)

orig_char = char.copy()
for i in orig_char:
    if i in ch.vocab:
        temp = ch.most_similar(i)
        for word, simi in temp:
            char.add(word)

orig_other = other.copy()
for i in orig_other:
    if i in ch.vocab:
        temp = ch.most_similar(i)
        for word, simi in temp:
            other.add(word)

X1 = []
for word in char:
    if word in ch.vocab:
        X1.append(ch[word])
X1 =  np.asarray(X1)

X2 = []
for word in loc:
    if word in ch.vocab:
        X2.append(ch[word])
X2 =  np.asarray(X2)

X3 = []
for word in other:
    if word in ch.vocab:
        X3.append(ch[word])
X3 =  np.asarray(X3)

X = np.concatenate((X1,X2,X3))

Y1 = np.full(238, 1)
Y2 = np.full(111, 2)
Y3 = np.full(98, 3)
Y = np.concatenate((Y1,Y2,Y3))


from sklearn.linear_model import LogisticRegression
#LogisticRegression
l_clf = LogisticRegression()
l_clf.fit(X,Y)


# return 1 if word is char
# return 2 if word is loc
# return 3 if word is neither
#
# 
# l_prediction = l_clf.predict([ch['詞']])
